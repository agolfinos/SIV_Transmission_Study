{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "Characterize the sequences in Nef RM9 epitope. Processes a folder hierarchy of FASTQ files and saves Nef RM9 sequences, counts and statistics files to a corresponding folder hierarchy. This script will generate a tsv file with nucleotide sequences and the number of times they are present in the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify dataset arguments\n",
    "\n",
    "Specify variables that need to be changed depending on the dataset and machine configuration. After these parameters are specified, the rest of the notebook should be runnable automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to FASTQ files to process\n",
    "# expects R1 and R2 paired samples\n",
    "FASTQ_FOLDER_PATH = 'Used_Files/'\n",
    "\n",
    "# path to folder containing barcode counts, intermediate files, and statistics\n",
    "OUTPUT_PATH = 'RM9_counts/'\n",
    "\n",
    "# path to bbmap\n",
    "BBMAP_PATH = 'bin/bbmap/'\n",
    "\n",
    "# path to reference file for read orientation\n",
    "REF_FASTA = 'ref/M33262.fasta'\n",
    "\n",
    "# 20bp of upstream and downstream sequences flanking Nef RM9\n",
    "UPSTREAM_FLANKING = 'ACTTGGTAGGGGTATCAGTG'\n",
    "DOWNSTREAM_FLANKING = 'AGTTACAAATTGGCAATAGA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Define functions that will be used in the workflow to count barcodes from FASTQ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logger\n",
    "\n",
    "def print_status(status):\n",
    "    '''print timestamped status update'''\n",
    "    \n",
    "    from datetime import datetime\n",
    "    import logging\n",
    "    \n",
    "    log = logging.getLogger(__name__)\n",
    "    \n",
    "    print('--[' + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '] ' + status + '--')\n",
    "    log.info(status)\n",
    "\n",
    "def create_temp_file():\n",
    "    '''create named temporary file\n",
    "    return temporary file object [0] and path to temporary file [1]'''\n",
    "\n",
    "    import pathlib\n",
    "    import tempfile\n",
    "    \n",
    "    temp = tempfile.NamedTemporaryFile()    \n",
    "    return [temp, temp.name]\n",
    "\n",
    "def create_directory(dir_path):\n",
    "    '''create directory at specified location if one does not already exist'''\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        \n",
    "    return dir_path\n",
    "\n",
    "def copy_and_overwrite(from_path, to_path):\n",
    "    '''duplicate folder and file hierarchy'''\n",
    "    import os\n",
    "    import shutil\n",
    "     \n",
    "    print_status('Copying files from ' + from_path + ' to ' + to_path)\n",
    "    if os.path.exists(to_path):\n",
    "        shutil.rmtree(to_path)\n",
    "    shutil.copytree(from_path, to_path)\n",
    "    \n",
    "def find_files_in_path(search_path):\n",
    "    '''get list of files matching files in search_path'''\n",
    "    import glob\n",
    "    \n",
    "    f = glob.glob(search_path, recursive=True)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def derive_file_name(source_file, find_string, replace_string):\n",
    "    '''create filename string '''\n",
    "    \n",
    "    f = source_file.replace(find_string, replace_string)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def run_command(cmd_list, stdout_file = None, stderr_file = None):\n",
    "    '''run command with subprocess.call\n",
    "    if stdout or stderr arguments are passed, save to specified file\n",
    "    '''\n",
    "    \n",
    "    import subprocess\n",
    "    \n",
    "    print_status(' '.join(cmd_list)) # print status\n",
    "    \n",
    "    # if neither stdout or stderr specified\n",
    "    if stdout_file is None and stderr_file is None:\n",
    "        print(cmd_list)\n",
    "        subprocess.call(cmd_list)\n",
    "     \n",
    "    # if only stdout is specified\n",
    "    elif stdout_file is not None and stderr_file is None:\n",
    "        with open(stdout_file, 'w') as so:\n",
    "            subprocess.call(cmd_list, stdout = so)\n",
    "     \n",
    "    # if only stderr is specified\n",
    "    elif stdout_file is None and stderr_file is not None:\n",
    "        with open(stderr_file, 'w') as se:\n",
    "            subprocess.call(cmd_list, stderr = se)\n",
    "     \n",
    "    # if both stdout and stderr are specified\n",
    "    elif stdout_file is not None and stderr_file is not None:\n",
    "        with open(stdout_file, 'w') as so:\n",
    "            with open(stderr_file, 'w') as se:\n",
    "                subprocess.call(cmd_list, stdout = so, stderr = se)\n",
    "    \n",
    "    else: pass\n",
    "    \n",
    "def split_path(source_file):\n",
    "    '''get path to enclosing folder and basename for source_file'''\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    source_file_path = os.path.dirname(source_file)\n",
    "    source_file_basename = os.path.basename(source_file)\n",
    "    \n",
    "    return [source_file_path, source_file_basename]\n",
    "\n",
    "def create_barcode_tsv(two_column_barcode_count_file, three_column_barcode_count_file, sample_name):\n",
    "    '''add a column with sample_name to barcode count TSV output by kmercountexact'''\n",
    "    \n",
    "    import pandas as pd \n",
    "    \n",
    "    # import file containing counts to pandas dataframe    \n",
    "    df = pd.read_csv(two_column_barcode_count_file, sep='\\t', names=['barcode_sequence', 'barcode_count'])\n",
    "    \n",
    "    # add column with sample name\n",
    "    df.insert(0, 'sample_name', sample_name)\n",
    "    \n",
    "    # export CSV with sample names added\n",
    "    df.to_csv(three_column_barcode_count_file, sep='\\t', index=False)\n",
    "    \n",
    "def remove_file(source_file):\n",
    "    '''remove file'''\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    os.remove(source_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "Count numbers of barcodes in FASTQ sequences by:\n",
    "\n",
    "1. Create folders to store barcode counts, intermediate files, and tools statistics\n",
    "1. Make dictionary of samples to process\n",
    "1. Iterate over every sample to process and:\n",
    "1. Quality trimming and merging R1 and R2 FASTQ sequences\n",
    "1. Extracting reads that contain the barcode\n",
    "1. Orient reads in same direction\n",
    "1. Trim reads to contain only the barcode\n",
    "1. Count number of times each barcode occurs\n",
    "1. Create TSV file with barcode counts for each sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "\n",
    "Checks if the output folder designated by the user exists, and creates it if not. The function then generates the output folder structure based on the input folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--[2019-09-20 09:19:03] Copying files from Used_Files/ to RM9_counts/--\n"
     ]
    }
   ],
   "source": [
    "## 1. Create folders to store barcode counts, intermediate files, and tools statistics ##\n",
    "\n",
    "copy_and_overwrite(from_path = FASTQ_FOLDER_PATH, to_path = OUTPUT_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \n",
    "\n",
    "Creates a dictionary of sample names, where the key is the sample directory path and the value is the file name sans forward/reverse designator and file extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Make dictionary of samples to process ##\n",
    "\n",
    "FASTQ_R1 = find_files_in_path(OUTPUT_PATH + '/**/*_R1_001.fastq.gz')\n",
    "\n",
    "SAMPLES = {}\n",
    "\n",
    "for i in FASTQ_R1:\n",
    "    \n",
    "    # get path to directory containing sample FASTQ\n",
    "    SAMPLE_DIR = split_path(i)[0]\n",
    "    \n",
    "    # get sample name\n",
    "    FASTQ_R1_BASENAME = split_path(i)[1]\n",
    "    SAMPLE_NAME = derive_file_name(FASTQ_R1_BASENAME, '_R1_001.fastq.gz', '')\n",
    "    \n",
    "    SAMPLES[i] = (SAMPLE_DIR, SAMPLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. \n",
    "\n",
    "Iterates over every sample in the dictionary to create a stats file and...\n",
    "\n",
    "### 4. \n",
    "\n",
    "Merges and quality trims the forward and reverse FASTQ reads using bbmerge. \n",
    "\n",
    "### 5. \n",
    "\n",
    "- Extracts reads containing the user-defined upstream flanking sequence, allowing for a 1 bp mismatch.\n",
    "- From those reads, extracts reads containing the user-defined downstream flanking sequence, again allowing for a 1 bp mismatch.\n",
    "\n",
    "### 6. \n",
    "\n",
    "- Maps reads to Zika virus reference using bbmap.\n",
    "- Using bbmap's splitsam utility, identifies plus and minus strands in the output sam file. Regenerates FASTQ files for plus and minus reads, and takes the reverse complement of the minus strands before concatenating the two files into a single FASTQ.\n",
    "\n",
    "### 7.\n",
    "\n",
    "Using bbduk, removes the upstream and downstream flanking sequences, again allowing for a 1 bp mismatch. By orienting the reads in Step 6, the upstream sequence can be left-trimmed and the downstream sequence can be right-trimmed without needing to account for reverse complements.\n",
    "\n",
    "### 8. \n",
    "\n",
    "Counts the number of times each 24mer barcode appears in each sample. By limiting to 24 bp, any PCR chimeras containing > 24 bp between flanking sequences are removed.\n",
    "\n",
    "### 9.\n",
    "\n",
    "Outputs a TSV file with barcode counts for each sequence, and removes temporary files created in the above steps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--[2019-09-20 09:19:05] bin/bbmap/bbmerge.sh in=RM9_counts/848-03_S3_L001_R1_001.fastq.gz in2=RM9_counts/848-03_S3_L001_R2_001.fastq.gz out=RM9_counts/848-03_S3_L001.merged.fastq.gz qtrim=t ow=t--\n",
      "--[2019-09-20 09:19:32] bin/bbmap/bbduk.sh in=RM9_counts/848-03_S3_L001.merged.fastq.gz outm=RM9_counts/848-03_S3_L001.containing_upstream_flank.fastq.gz literal=ACTTGGTAGGGGTATCAGTG k=20 hdist=1 ow=t--\n",
      "--[2019-09-20 09:19:36] bin/bbmap/bbduk.sh in=RM9_counts/848-03_S3_L001.containing_upstream_flank.fastq.gz outm=RM9_counts/848-03_S3_L001.containing_barcode.fastq.gz literal=AGTTACAAATTGGCAATAGA k=20 hdist=1 ow=t--\n",
      "--[2019-09-20 09:19:37] bin/bbmap/bbmap.sh in=RM9_counts/848-03_S3_L001.containing_barcode.fastq.gz outm=RM9_counts/848-03_S3_L001.mapped.sam ref=ref/M33262.fasta ow=t--\n",
      "--[2019-09-20 09:19:54] bin/bbmap/splitsam.sh RM9_counts/848-03_S3_L001.mapped.sam /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpabekmgz0.sam /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp9bh11k1b.sam /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmptpoq1aal.sam--\n",
      "['bin/bbmap/splitsam.sh', 'RM9_counts/848-03_S3_L001.mapped.sam', '/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpabekmgz0.sam', '/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp9bh11k1b.sam', '/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmptpoq1aal.sam']\n",
      "--[2019-09-20 09:19:54] bin/bbmap/reformat.sh in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpabekmgz0.sam out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpogajgorz.fastq.gz--\n",
      "['bin/bbmap/reformat.sh', 'in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpabekmgz0.sam', 'out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpogajgorz.fastq.gz']\n",
      "--[2019-09-20 09:19:55] bin/bbmap/reformat.sh in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp9bh11k1b.sam out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpdykq2s37.fastq.gz rcomp=t--\n",
      "['bin/bbmap/reformat.sh', 'in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp9bh11k1b.sam', 'out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpdykq2s37.fastq.gz', 'rcomp=t']\n",
      "--[2019-09-20 09:19:56] cat /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpogajgorz.fastq.gz /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpdykq2s37.fastq.gz--\n",
      "--[2019-09-20 09:19:56] bin/bbmap/bbduk.sh in=RM9_counts/848-03_S3_L001.oriented.fastq.gz out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp69ok4w8p.fastq.gz literal=ACTTGGTAGGGGTATCAGTG ktrim=l rcomp=f k=20 hdist=1 ow=t--\n",
      "--[2019-09-20 09:19:56] bin/bbmap/bbduk.sh in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp69ok4w8p.fastq.gz out=RM9_counts/848-03_S3_L001.barcodes.fastq.gz literal=AGTTACAAATTGGCAATAGA ktrim=r rcomp=f k=20 hdist=1 minlength=27 maxlength=27 ow=t--\n",
      "--[2019-09-20 09:19:57] bin/bbmap/kmercountexact.sh in=RM9_counts/848-03_S3_L001.barcodes.fastq.gz out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp_jntls0_.txt fastadump=f k=27 rcomp=f--\n",
      "['bin/bbmap/kmercountexact.sh', 'in=RM9_counts/848-03_S3_L001.barcodes.fastq.gz', 'out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp_jntls0_.txt', 'fastadump=f', 'k=27', 'rcomp=f']\n",
      "--[2019-09-20 09:19:59] bin/bbmap/bbmerge.sh in=RM9_counts/1253-18_S16_L001_R1_001.fastq.gz in2=RM9_counts/1253-18_S16_L001_R2_001.fastq.gz out=RM9_counts/1253-18_S16_L001.merged.fastq.gz qtrim=t ow=t--\n",
      "--[2019-09-20 09:20:13] bin/bbmap/bbduk.sh in=RM9_counts/1253-18_S16_L001.merged.fastq.gz outm=RM9_counts/1253-18_S16_L001.containing_upstream_flank.fastq.gz literal=ACTTGGTAGGGGTATCAGTG k=20 hdist=1 ow=t--\n",
      "--[2019-09-20 09:20:15] bin/bbmap/bbduk.sh in=RM9_counts/1253-18_S16_L001.containing_upstream_flank.fastq.gz outm=RM9_counts/1253-18_S16_L001.containing_barcode.fastq.gz literal=AGTTACAAATTGGCAATAGA k=20 hdist=1 ow=t--\n",
      "--[2019-09-20 09:20:15] bin/bbmap/bbmap.sh in=RM9_counts/1253-18_S16_L001.containing_barcode.fastq.gz outm=RM9_counts/1253-18_S16_L001.mapped.sam ref=ref/M33262.fasta ow=t--\n",
      "--[2019-09-20 09:20:26] bin/bbmap/splitsam.sh RM9_counts/1253-18_S16_L001.mapped.sam /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmppj0tqunc.sam /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp2sobn1w2.sam /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpew_9uuda.sam--\n",
      "['bin/bbmap/splitsam.sh', 'RM9_counts/1253-18_S16_L001.mapped.sam', '/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmppj0tqunc.sam', '/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp2sobn1w2.sam', '/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpew_9uuda.sam']\n",
      "--[2019-09-20 09:20:26] bin/bbmap/reformat.sh in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmppj0tqunc.sam out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpoqtp905k.fastq.gz--\n",
      "['bin/bbmap/reformat.sh', 'in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmppj0tqunc.sam', 'out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpoqtp905k.fastq.gz']\n",
      "--[2019-09-20 09:20:27] bin/bbmap/reformat.sh in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp2sobn1w2.sam out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpdaxz96dv.fastq.gz rcomp=t--\n",
      "['bin/bbmap/reformat.sh', 'in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp2sobn1w2.sam', 'out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpdaxz96dv.fastq.gz', 'rcomp=t']\n",
      "--[2019-09-20 09:20:28] cat /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpoqtp905k.fastq.gz /var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpdaxz96dv.fastq.gz--\n",
      "--[2019-09-20 09:20:28] bin/bbmap/bbduk.sh in=RM9_counts/1253-18_S16_L001.oriented.fastq.gz out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpuk9cjspp.fastq.gz literal=ACTTGGTAGGGGTATCAGTG ktrim=l rcomp=f k=20 hdist=1 ow=t--\n",
      "--[2019-09-20 09:20:28] bin/bbmap/bbduk.sh in=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmpuk9cjspp.fastq.gz out=RM9_counts/1253-18_S16_L001.barcodes.fastq.gz literal=AGTTACAAATTGGCAATAGA ktrim=r rcomp=f k=20 hdist=1 minlength=27 maxlength=27 ow=t--\n",
      "--[2019-09-20 09:20:29] bin/bbmap/kmercountexact.sh in=RM9_counts/1253-18_S16_L001.barcodes.fastq.gz out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp4dl5i5qo.txt fastadump=f k=27 rcomp=f--\n",
      "['bin/bbmap/kmercountexact.sh', 'in=RM9_counts/1253-18_S16_L001.barcodes.fastq.gz', 'out=/var/folders/lz/b8xzxdf952bck9bb57k2d4yr0000gq/T/tmp4dl5i5qo.txt', 'fastadump=f', 'k=27', 'rcomp=f']\n"
     ]
    }
   ],
   "source": [
    "## 3. Iterate over every sample to process and: ##\n",
    "\n",
    "for key,val in SAMPLES.items():\n",
    "    \n",
    "    # get sample path and sample name\n",
    "    SAMPLE_PATH = val[0]\n",
    "    SAMPLE_NAME = val[1]\n",
    "    \n",
    "    # create directory to hold statistics files\n",
    "    STATS_PATH = create_directory(SAMPLE_PATH + '/stats')\n",
    "\n",
    "    ## 4. Quality trimming and merging R1 and R2 FASTQ sequences ##\n",
    "    \n",
    "    # merge and quality trim\n",
    "    run_command([BBMAP_PATH + 'bbmerge.sh',\n",
    "                 'in=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '_R1_001.fastq.gz',\n",
    "                 'in2=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '_R2_001.fastq.gz',\n",
    "                 'out=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.merged.fastq.gz',\n",
    "                 'qtrim=t',\n",
    "                 'ow=t'],\n",
    "                 stderr_file = STATS_PATH + '/' + SAMPLE_NAME + '.merging.stats.txt')\n",
    "    \n",
    "    ## 5. Extracting reads that contain the barcode ##\n",
    "    \n",
    "    # extract reads containing barcode\n",
    "    # bbduk command to find reads containing upstream flanking sequence   \n",
    "    run_command([BBMAP_PATH + 'bbduk.sh',\n",
    "                  'in=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.merged.fastq.gz',\n",
    "                  'outm=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.containing_upstream_flank.fastq.gz',\n",
    "                  'literal=' + UPSTREAM_FLANKING,\n",
    "                  'k=20',\n",
    "                  'hdist=1',\n",
    "                  'ow=t'],\n",
    "                  stderr_file = STATS_PATH + '/' + SAMPLE_NAME + '.containing_upstream_flank.stats.txt')\n",
    "    \n",
    "    # bbduk command to find reads containing downstream flanking sequence \n",
    "    # (among those that contain upstream flanking sequence)\n",
    "    run_command([BBMAP_PATH + 'bbduk.sh',\n",
    "                  'in=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.containing_upstream_flank.fastq.gz',\n",
    "                  'outm=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.containing_barcode.fastq.gz',\n",
    "                  'literal=' + DOWNSTREAM_FLANKING,\n",
    "                  'k=20',\n",
    "                  'hdist=1',\n",
    "                  'ow=t'],\n",
    "                  stderr_file=STATS_PATH + '/' + SAMPLE_NAME + '.containing_barcode.stats.txt')\n",
    "    \n",
    "    ## 6. Orient reads in same direction ##title\n",
    "    \n",
    "    # orient reads by mapping to reference\n",
    "    # use SIV reference with accession M33262\n",
    "    run_command([BBMAP_PATH + 'bbmap.sh',\n",
    "                'in=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.containing_barcode.fastq.gz',\n",
    "                'outm=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.mapped.sam',\n",
    "                'ref=' + REF_FASTA,\n",
    "                'ow=t'],\n",
    "                stderr_file=STATS_PATH + '/' + SAMPLE_NAME + '.mapping.stats.txt')\n",
    "    \n",
    "    # split mapped SAM file into plus, minus, and unmapped strand SAM temporary files\n",
    "    PLUS_STRAND_SAM = create_temp_file()\n",
    "    MINUS_STRAND_SAM = create_temp_file()\n",
    "    UNMAPPED_STRAND_SAM = create_temp_file()\n",
    "    \n",
    "    run_command([BBMAP_PATH + 'splitsam.sh',\n",
    "                SAMPLE_PATH + '/' + SAMPLE_NAME + '.mapped.sam',\n",
    "                PLUS_STRAND_SAM[1] + '.sam',\n",
    "                MINUS_STRAND_SAM[1] + '.sam',\n",
    "                UNMAPPED_STRAND_SAM[1] + '.sam'])    \n",
    "    \n",
    "    # reformat plus and minus strand SAM files to FASTQ\n",
    "    PLUS_STRAND_FASTQ = create_temp_file()\n",
    "    MINUS_STRAND_FASTQ = create_temp_file()    \n",
    "\n",
    "    run_command([BBMAP_PATH + 'reformat.sh',\n",
    "                'in=' + PLUS_STRAND_SAM[1] + '.sam',\n",
    "                'out=' + PLUS_STRAND_FASTQ[1] + '.fastq.gz'])\n",
    "                 \n",
    "    run_command([BBMAP_PATH + 'reformat.sh',\n",
    "                'in=' + MINUS_STRAND_SAM[1] + '.sam',\n",
    "                'out=' + MINUS_STRAND_FASTQ[1] + '.fastq.gz',\n",
    "                'rcomp=t'])\n",
    "    \n",
    "    # concatenate oriented plus and minus strand FASTQ\n",
    "    run_command(['cat',\n",
    "                PLUS_STRAND_FASTQ[1] + '.fastq.gz',\n",
    "                MINUS_STRAND_FASTQ[1] + '.fastq.gz'],\n",
    "               stdout_file = SAMPLE_PATH + '/' + SAMPLE_NAME + '.oriented.fastq.gz')\n",
    "    \n",
    "    ## 7. Trim reads to contain only the barcode ##\n",
    "    \n",
    "    # remove upstream flanking sequence from oriented reads\n",
    "    UPSTREAM_FLANK_REMOVED = create_temp_file()\n",
    "    \n",
    "    run_command([BBMAP_PATH + 'bbduk.sh',\n",
    "               'in=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.oriented.fastq.gz',\n",
    "               'out=' + UPSTREAM_FLANK_REMOVED[1] + '.fastq.gz',\n",
    "               'literal=' + UPSTREAM_FLANKING,\n",
    "               'ktrim=l',\n",
    "               'rcomp=f',\n",
    "               'k=20',\n",
    "               'hdist=1',\n",
    "               'ow=t'],\n",
    "               stderr_file = STATS_PATH + '/' + SAMPLE_NAME + '.upstream.flank.removal.stats.txt')\n",
    "    \n",
    "    # remove downstream flanking sequence from oriented reads\n",
    "    run_command([BBMAP_PATH + 'bbduk.sh',\n",
    "               'in=' + UPSTREAM_FLANK_REMOVED[1] + '.fastq.gz',\n",
    "               'out=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.barcodes.fastq.gz',\n",
    "               'literal=' + DOWNSTREAM_FLANKING,\n",
    "               'ktrim=r',\n",
    "               'rcomp=f',\n",
    "               'k=20',\n",
    "               'hdist=1',\n",
    "               'minlength=27',  \n",
    "               'maxlength=27',\n",
    "               'ow=t'],\n",
    "               stderr_file = STATS_PATH + '/' + SAMPLE_NAME + '.downstream.flank.removal.stats.txt')\n",
    "    \n",
    "    \n",
    "    ## 8. Count number of times each barcode occurs ##\n",
    "    \n",
    "    # count number of identical barcodes in each sample\n",
    "    \n",
    "    # create temporary count file\n",
    "    BARCODE_COUNT_TEMP = create_temp_file()\n",
    "    \n",
    "    run_command([BBMAP_PATH + 'kmercountexact.sh',\n",
    "          'in=' + SAMPLE_PATH + '/' + SAMPLE_NAME + '.barcodes.fastq.gz',\n",
    "          'out=' + BARCODE_COUNT_TEMP[1] + '.txt',\n",
    "          'fastadump=f',\n",
    "          'k=27',\n",
    "          'rcomp=f'])\n",
    "#took last argument out of this, which was 'ow=t'. I couldn't find this in the documentation\n",
    "    \n",
    "    ## 9. Create TSV file with barcode counts for each sequence ##\n",
    "    \n",
    "    # create three column barcode count file with sample name\n",
    "    create_barcode_tsv(BARCODE_COUNT_TEMP[1] + '.txt',\n",
    "                       SAMPLE_PATH + '/' + SAMPLE_NAME + '.Nef_RM9_barcode_counts.txt',\n",
    "                       SAMPLE_NAME)\n",
    "    \n",
    "    # remove temporary files\n",
    "    PLUS_STRAND_SAM[0].close()\n",
    "    PLUS_STRAND_FASTQ[0].close()\n",
    "    MINUS_STRAND_SAM[0].close()\n",
    "    MINUS_STRAND_FASTQ[0].close()\n",
    "    UNMAPPED_STRAND_SAM[0].close()\n",
    "    UPSTREAM_FLANK_REMOVED[0].close()\n",
    "    BARCODE_COUNT_TEMP\n",
    "    \n",
    "    # remove intermediate files\n",
    "    # copies of these already exist in 02-renamed_fastq/\n",
    "    #remove_file(SAMPLE_PATH + '/' + SAMPLE_NAME + '_R1.fastq.gz')\n",
    "    #remove_file(SAMPLE_PATH + '/' + SAMPLE_NAME + '_R2.fastq.gz')\n",
    "    #remove_file(SAMPLE_PATH + '/' + SAMPLE_NAME + '.merged.fastq.gz')\n",
    "    #remove_file(SAMPLE_PATH + '/' + SAMPLE_NAME + '.containing_upstream_flank.fastq.gz')\n",
    "    #remove_file(SAMPLE_PATH + '/' + SAMPLE_NAME + '.containing_barcode.fastq.gz')\n",
    "    #remove_file(SAMPLE_PATH + '/' + SAMPLE_NAME + '.mapped.sam')\n",
    "    #remove_file(SAMPLE_PATH + '/' + SAMPLE_NAME + '.oriented.fastq.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
